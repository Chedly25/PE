{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections.abc\n",
    "#hyper needs the four following aliases to be done manually.\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "collections.Mapping = collections.abc.Mapping\n",
    "collections.MutableSet = collections.abc.MutableSet\n",
    "collections.MutableMapping = collections.abc.MutableMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from os import path\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "#import pandas as pd\n",
    "import pickle\n",
    "import mne\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from dn3.configuratron import ExperimentConfig\n",
    "from dn3.data.dataset import Thinker, RawTorchRecording\n",
    "from dn3.trainable.processes import StandardClassification\n",
    "\n",
    "from dn3_ext import BENDRClassification, LinearHeadBENDR\n",
    "import torch\n",
    "import tqdm\n",
    "import utils\n",
    "import argparse\n",
    "\n",
    "# Since we are doing a lot of loading, this is nice to suppress some tedious information\n",
    "import mne\n",
    "\n",
    "mne.set_log_level(False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--ds-config DS_CONFIG]\n",
      "                             [--metrics-config METRICS_CONFIG]\n",
      "                             [--subject-specific] [--mdl] [--freeze-encoder]\n",
      "                             [--random-init] [--multi-gpu]\n",
      "                             [--num-workers NUM_WORKERS]\n",
      "                             [--results-filename RESULTS_FILENAME]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\chedl\\AppData\\Roaming\\jupyter\\runtime\\kernel-643a1e93-ce5d-40ba-9ef3-f0e565c2c9b7.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[1;31mSystemExit\u001B[0m\u001B[1;31m:\u001B[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Fine-tunes BENDER models.\")\n",
    "# parser.add_argument('-data', choices=utils.CUSTOM_LOADERS)\n",
    "parser.add_argument('--ds-config', default=\"configs/downstream.yml\", help=\"The DN3 config file to use.\")\n",
    "parser.add_argument('--metrics-config', default=\"configs/metrics.yml\", help=\"Where the listings for config \"\n",
    "                                                                                    \"metrics are stored.\")\n",
    "parser.add_argument('--subject-specific', action='store_true', help=\"Fine-tune on target subject alone.\")\n",
    "parser.add_argument('--mdl', action='store_true', help=\"Fine-tune on target subject using all extra data.\")\n",
    "parser.add_argument('--freeze-encoder', action='store_true', help=\"Whether to keep the encoder stage frozen. \"\n",
    "                                                                          \"Will only be done if not randomly initialized.\")\n",
    "parser.add_argument('--random-init', action='store_true', help='Randomly initialized BENDR for comparison.')\n",
    "parser.add_argument('--multi-gpu', action='store_true', help='Distribute BENDR over multiple GPUs')\n",
    "parser.add_argument('--num-workers', default=4, type=int, help='Number of dataloader workers.')\n",
    "parser.add_argument('--results-filename', default=None, help='What to name the spreadsheet produced with all '\n",
    "                                                                     'final results.')\n",
    "args = parser.parse_args()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m experiment \u001B[38;5;241m=\u001B[39m ExperimentConfig(\u001B[43margs\u001B[49m\u001B[38;5;241m.\u001B[39mds_config)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ds_name, ds \u001B[38;5;129;01min\u001B[39;00m tqdm\u001B[38;5;241m.\u001B[39mtqdm(experiment\u001B[38;5;241m.\u001B[39mdatasets\u001B[38;5;241m.\u001B[39mitems(), total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(experiment\u001B[38;5;241m.\u001B[39mdatasets\u001B[38;5;241m.\u001B[39mitems()),\n\u001B[0;32m      3\u001B[0m                         desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDatasets\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m      4\u001B[0m     added_metrics, retain_best, _ \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mget_ds_added_metrics(ds_name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfigs/metrics.yml\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "experiment = ExperimentConfig(args.ds_config)\n",
    "for ds_name, ds in tqdm.tqdm(experiment.datasets.items(), total=len(experiment.datasets.items()),\n",
    "                        desc='Datasets'):\n",
    "    added_metrics, retain_best, _ = utils.get_ds_added_metrics(ds_name, \"configs/metrics.yml\")\n",
    "    for fold, (training, validation, test) in enumerate(tqdm.tqdm(utils.get_lmoso_iterator(ds_name, ds))):\n",
    "        #tqdm.tqdm.write(torch.cuda.memory_summary())\n",
    "        #dummy_tensor = torch.tensor([1, 0, 1, 1, 0, 0, 1, 1])\n",
    "        #training = training + (dummy_tensor,)\n",
    "        model = BENDRClassification.from_dataset(training)\n",
    "        if not args.random_init:\n",
    "            model.load_pretrained_modules(experiment.encoder_weights, experiment.context_weights,\n",
    "                                            freeze_encoder=args.freeze_encoder)\n",
    "        process = StandardClassification(model, metrics=added_metrics)\n",
    "        process.set_optimizer(torch.optim.Adam(process.parameters(), ds.lr, weight_decay=0.01))\n",
    "\n",
    "        # Fit everything\n",
    "        process.fit(training_dataset=training, validation_dataset=validation, warmup_frac=0.1,\n",
    "                    retain_best=retain_best, pin_memory=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'configs/downstream_datasets.yml'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m experiment \u001B[38;5;241m=\u001B[39m \u001B[43mExperimentConfig\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mC:\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mUsers\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mchedl\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mOneDrive\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mBureau\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mEMSE\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43m3A\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mPE\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mPE\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mconfigs\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mdownstream.yml\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ds_name, ds \u001B[38;5;129;01min\u001B[39;00m tqdm\u001B[38;5;241m.\u001B[39mtqdm(experiment\u001B[38;5;241m.\u001B[39mdatasets\u001B[38;5;241m.\u001B[39mitems(), total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(experiment\u001B[38;5;241m.\u001B[39mdatasets\u001B[38;5;241m.\u001B[39mitems()),\n\u001B[0;32m      3\u001B[0m                 desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDatasets\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m      4\u001B[0m     added_metrics, retain_best, _ \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mget_ds_added_metrics(ds_name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfigs/metrics.yml\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\dn3\\configuratron\\config.py:97\u001B[0m, in \u001B[0;36mExperimentConfig.__init__\u001B[1;34m(self, config_filename, adopt_auxiliaries)\u001B[0m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;124;03mParses DN3 configuration files. Checking the DN3 token for listed datasets.\u001B[39;00m\n\u001B[0;32m     87\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;124;03m                     object for later use. Defaults to True. This will propagate for the detected datasets.\u001B[39;00m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(config_filename, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m fio:\n\u001B[1;32m---> 97\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_config \u001B[38;5;241m=\u001B[39m \u001B[43myaml\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mLoader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43myaml\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFullLoader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     98\u001B[0m working_config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_config\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m    100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mConfiguratron\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m working_config\u001B[38;5;241m.\u001B[39mkeys():\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\__init__.py:114\u001B[0m, in \u001B[0;36mload\u001B[1;34m(stream, Loader)\u001B[0m\n\u001B[0;32m    112\u001B[0m loader \u001B[38;5;241m=\u001B[39m Loader(stream)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mloader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_single_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    116\u001B[0m     loader\u001B[38;5;241m.\u001B[39mdispose()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\constructor.py:51\u001B[0m, in \u001B[0;36mBaseConstructor.get_single_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     49\u001B[0m node \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_single_node()\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m node \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstruct_document\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\constructor.py:60\u001B[0m, in \u001B[0;36mBaseConstructor.construct_document\u001B[1;34m(self, node)\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate_generators \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m generator \u001B[38;5;129;01min\u001B[39;00m state_generators:\n\u001B[1;32m---> 60\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m dummy \u001B[38;5;129;01min\u001B[39;00m generator:\n\u001B[0;32m     61\u001B[0m             \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconstructed_objects \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\constructor.py:413\u001B[0m, in \u001B[0;36mSafeConstructor.construct_yaml_map\u001B[1;34m(self, node)\u001B[0m\n\u001B[0;32m    411\u001B[0m data \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    412\u001B[0m \u001B[38;5;28;01myield\u001B[39;00m data\n\u001B[1;32m--> 413\u001B[0m value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstruct_mapping\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    414\u001B[0m data\u001B[38;5;241m.\u001B[39mupdate(value)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\constructor.py:218\u001B[0m, in \u001B[0;36mSafeConstructor.construct_mapping\u001B[1;34m(self, node, deep)\u001B[0m\n\u001B[0;32m    216\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(node, MappingNode):\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mflatten_mapping(node)\n\u001B[1;32m--> 218\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstruct_mapping\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdeep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdeep\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\constructor.py:143\u001B[0m, in \u001B[0;36mBaseConstructor.construct_mapping\u001B[1;34m(self, node, deep)\u001B[0m\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, collections\u001B[38;5;241m.\u001B[39mabc\u001B[38;5;241m.\u001B[39mHashable):\n\u001B[0;32m    141\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ConstructorError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwhile constructing a mapping\u001B[39m\u001B[38;5;124m\"\u001B[39m, node\u001B[38;5;241m.\u001B[39mstart_mark,\n\u001B[0;32m    142\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound unhashable key\u001B[39m\u001B[38;5;124m\"\u001B[39m, key_node\u001B[38;5;241m.\u001B[39mstart_mark)\n\u001B[1;32m--> 143\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstruct_object\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue_node\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdeep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdeep\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    144\u001B[0m     mapping[key] \u001B[38;5;241m=\u001B[39m value\n\u001B[0;32m    145\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m mapping\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yaml\\constructor.py:100\u001B[0m, in \u001B[0;36mBaseConstructor.construct_object\u001B[1;34m(self, node, deep)\u001B[0m\n\u001B[0;32m     98\u001B[0m             constructor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39mconstruct_mapping\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tag_suffix \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 100\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mconstructor\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    101\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    102\u001B[0m     data \u001B[38;5;241m=\u001B[39m constructor(\u001B[38;5;28mself\u001B[39m, tag_suffix, node)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yamlinclude\\constructor.py:76\u001B[0m, in \u001B[0;36mYamlIncludeConstructor.__call__\u001B[1;34m(self, loader, node)\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUn-supported YAML node \u001B[39m\u001B[38;5;132;01m{!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(node))\n\u001B[1;32m---> 76\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mload(loader, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yamlinclude\\constructor.py:162\u001B[0m, in \u001B[0;36mYamlIncludeConstructor.load\u001B[1;34m(self, loader, pathname, recursive, encoding, reader)\u001B[0m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reader_clz:\n\u001B[0;32m    161\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m reader_clz(pathname, encoding\u001B[38;5;241m=\u001B[39mencoding, loader_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mtype\u001B[39m(loader))()\n\u001B[1;32m--> 162\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpathname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yamlinclude\\constructor.py:167\u001B[0m, in \u001B[0;36mYamlIncludeConstructor._read_file\u001B[1;34m(self, path, loader, encoding)\u001B[0m\n\u001B[0;32m    165\u001B[0m reader_clz \u001B[38;5;241m=\u001B[39m get_reader_class_by_path(path, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reader_map)\n\u001B[0;32m    166\u001B[0m reader_obj \u001B[38;5;241m=\u001B[39m reader_clz(path, encoding\u001B[38;5;241m=\u001B[39mencoding, loader_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mtype\u001B[39m(loader))\n\u001B[1;32m--> 167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mreader_obj\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\yamlinclude\\readers.py:75\u001B[0m, in \u001B[0;36mYamlReader.__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 75\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_encoding\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m fp:  \u001B[38;5;66;03m# pylint:disable=invalid-name\u001B[39;00m\n\u001B[0;32m     76\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m yaml\u001B[38;5;241m.\u001B[39mload(fp, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loader_class)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'configs/downstream_datasets.yml'"
     ]
    }
   ],
   "source": [
    "experiment = ExperimentConfig('C:\\\\Users\\\\chedl\\\\OneDrive\\\\Bureau\\\\EMSE\\\\3A\\\\PE\\\\PE\\\\configs\\\\downstream.yml')\n",
    "for ds_name, ds in tqdm.tqdm(experiment.datasets.items(), total=len(experiment.datasets.items()),\n",
    "                desc='Datasets'):\n",
    "    added_metrics, retain_best, _ = utils.get_ds_added_metrics(ds_name, \"configs/metrics.yml\")\n",
    "    for fold, (training, validation, test) in enumerate(tqdm.tqdm(utils.get_lmoso_iterator(ds_name, ds))):\n",
    "        #tqdm.tqdm.write(torch.cuda.memory_summary())\n",
    "        #dummy_tensor = torch.tensor([1, 0, 1, 1, 0, 0, 1, 1])\n",
    "        #training = training + (dummy_tensor,)\n",
    "        model = BENDRClassification.from_dataset(training)\n",
    "        model.load_pretrained_modules(experiment.encoder_weights, experiment.context_weights)\n",
    "        process = StandardClassification(model, metrics=added_metrics)\n",
    "        process.set_optimizer(torch.optim.Adam(process.parameters(), ds.lr, weight_decay=0.01))\n",
    "\n",
    "        # Fit everything\n",
    "        process.fit(training_dataset=training, validation_dataset=validation, warmup_frac=0.1,\n",
    "                retain_best=retain_best, pin_memory=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
