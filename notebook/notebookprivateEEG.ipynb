{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import collections.abc\n",
    "#hyper needs the four following aliases to be done manually.\\n\",\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "collections.Mapping = collections.abc.Mapping\n",
    "collections.MutableSet = collections.abc.MutableSet\n",
    "collections.MutableMapping = collections.abc.MutableMapping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from os import path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import mne\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def from_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        obj = pickle.load(f)\n",
    "    return obj"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "547"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_raw_EEG = 'C:\\\\\\\\Users\\\\\\\\chedl\\\\\\\\OneDrive\\\\\\\\Bureau\\\\\\\\EMSE\\\\\\\\3A\\\\\\\\PE\\\\\\\\privateData\\\\\\\\EEG_MAHNOB_Dictinary.p'\n",
    "path_raw_data = 'C:\\\\\\\\Users\\\\\\\\chedl\\\\\\\\OneDrive\\\\\\\\Bureau\\\\\\\\EMSE\\\\\\\\3A\\\\\\\\PE\\\\\\\\privateData\\\\\\\\Metadata_dict.p'\n",
    "all_eeg = from_pickle(path_raw_EEG)\n",
    "meta = from_pickle(path_raw_data)\n",
    "labels = from_pickle(path.join(path_raw_data, \"Label_Dict.p\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EEG_channels = ['Fp1', 'AF3', 'F3', 'F7', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'P3',\n",
    "                'P7', 'PO3', 'O1', 'Oz', 'Pz', 'Fp2', 'AF4', 'Fz', 'F4', 'F8', 'FC6',\n",
    "                'FC2', 'Cz', 'C4', 'T8', 'CP6', 'CP2', 'P4', 'P8', 'PO4', 'O2']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_raw_data = \"C:\\\\Users\\\\chedl\\\\OneDrive\\\\Bureau\\\\EMSE\\\\3A\\\\PE\\\\privateData\"\n",
    "# Merge the two dictionaries\n",
    "merged_dict = {}\n",
    "for subject_id, session_ids in meta.items():\n",
    "    for session_id in session_ids['sessionId']:\n",
    "    # Get the recordings for this session\\n\",\n",
    "        recordings = all_eeg.get(session_id, [])\n",
    "    # Update the merged dictionary with the participant ID, session ID, and recordings\n",
    "        merged_dict.update({(subject_id, session_id): recordings})\n",
    "    # Print the merged dictionary\n",
    "#print(meta)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = 'C:\\\\\\\\Users\\\\\\\\chedl\\\\\\\\OneDrive\\\\\\\\Bureau\\\\\\\\EMSE\\\\\\\\3A\\\\\\\\PE\\\\\\\\essai'\n",
    "# Set the path of the directory where you want to create the new directories\n",
    "# Create 30 directories with names corresponding to their numbers in the specified directory\\n\",\n",
    "for i in range(1, 31):\n",
    "    dir_name = f'{i}'\n",
    "    os.mkdir(os.path.join(path, dir_name))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Iterate through the subject IDs and their corresponding data dictionaries\\n\",\n",
    "for subject_id, subject_session in meta.items():\n",
    "    # Create the path to the subject directory\n",
    "    subject_dir_path = os.path.join(path, str(subject_id))\n",
    "    # Open the subject directory\n",
    "    os.startfile(subject_dir_path)\n",
    "\n",
    "    # Iterate through the session IDs and their corresponding data dictionaries for the current subject\n",
    "    #for session_id, session_data in all_eeg.items():\n",
    "    for session in subject_session['sessionId']:\n",
    "        #Create the path to the session directory\n",
    "        #session_dir_path = os.path.join(subject_dir_path, str(session))\n",
    "        # Open the session directory\n",
    "        #os.startfile(session_dir_path)\n",
    "        session_data = all_eeg[session]\n",
    "        session_data = session_data.reshape(32, -1)\n",
    "        # Create a Raw object from the numpy array\n",
    "        raw = mne.io.RawArray(session_data, info=mne.create_info(ch_names= EEG_channels, sfreq=1000))\n",
    "        # Create the filename for the EDF file\n",
    "        edf_filename = f\"recording_{session}.raw.fif\"\n",
    "        # Write the Raw object to an EDF file in the current session's directory\n",
    "        edf_path = os.path.join(subject_dir_path, edf_filename)\n",
    "        raw.save(edf_path, overwrite=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(1, 31):\n",
    "    # Construct the path to the current subdirectory\n",
    "    subdir = os.path.join(path, str(i))\n",
    "    # Check if the subdirectory exists\n",
    "    if os.path.exists(subdir) and os.path.isdir(subdir):\n",
    "    # Loop through all the files in the subdirectory\n",
    "        for file in os.listdir(subdir):\n",
    "            # Check if the file is a .raw.fif file\n",
    "            if file.endswith('.raw.fif'):\n",
    "                # Construct the full path to the .raw.fif file\n",
    "                raw_file = os.path.join(subdir, file)\n",
    "\n",
    "                # Construct the full path to the .edf file\n",
    "                edf_file = os.path.join(subdir, file[:-8] + '.edf')\n",
    "\n",
    "                # Load the .raw.fif data\n",
    "                raw = mne.io.read_raw_fif(raw_file)\n",
    "                # Save the data as .edf, overwriting the existing file\n",
    "                raw.save(edf_file, overwrite=True)\n",
    "\n",
    "                # Delete the original .raw.fif file\n",
    "                os.remove(raw_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eeg = all_eeg[2][2]\n",
    "eeg_data = all_eeg[2]\n",
    "eeg_channels = EEG_channels\n",
    "# Create the plot\\n\",\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(eeg)\n",
    "# Set up the figure and axes\n",
    "fig, axes = plt.subplots(nrows=len(eeg_channels), figsize=(200, 200))\n",
    "# Set the plot title and axis labels\\n\",\n",
    "ax.set_title(\"EEG Signal\")\n",
    "ax.set_xlabel(\"Time (samples)\")\n",
    "ax.set_ylabel(\"Voltage (uV)\")\n",
    "# Loop through each channel and plot the corresponding EEG data\\n\",\n",
    "for i, channel in enumerate(eeg_channels):\n",
    "    axes[i].plot(eeg_data[:, i])\n",
    "    axes[i].set_title(channel)\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from dn3.configuratron import ExperimentConfig, DatasetConfig\n",
    "from dn3.trainable.processes import StandardClassification\n",
    "from dn3.trainable.models import TIDNet\n",
    "# Since we are doing a lot of loading, this is nice to suppress some tedious information\\n\",\n",
    "import mne\n",
    "mne.set_log_level(False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config_filename = 'privateEEG_config.yml'\n",
    "experiment = ExperimentConfig(config_filename)\n",
    "ds_config = experiment.datasets['privateEEG']\n",
    "dataset = ds_config.auto_construct_dataset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_model_and_process():\n",
    "    tidnet = TIDNet.from_dataset(dataset)\n",
    "    return StandardClassification(tidnet, cuda=experiment.use_gpu, learning_rate=ds_config.train_params.lr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = list()\n",
    "for training, validation, test in dataset.lmso(ds_config.train_params.folds):\n",
    "    process = make_model_and_process()\n",
    "    process.fit(training_dataset=training, validation_dataset=validation)\n",
    "    results.append(process.evaluate(test)['Accuracy'])\n",
    "    print(results)\n",
    "    print(\"Average accuracy: {:.2%}\".format(sum(results)/len(results)))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
